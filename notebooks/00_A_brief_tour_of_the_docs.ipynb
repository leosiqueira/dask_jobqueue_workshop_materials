{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A tour of the Dask-Jobqueue docs\n",
    "\n",
    "The Dask-Jobqueue docs are a concise resource for most of the specifics of deploying / running Dask clusters on HPC.  They are here: <https://jobqueue.dask.org/>\n",
    "\n",
    "As Dask-Jobqueue closely follows the development of Dask.distributed, you'll often find yourself looking at the docs of distributed as well.  They are here: <https://distributed.dask.org/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "There's different ways of installing that are outlined in the docs.\n",
    "\n",
    "Note that dask jobqueue is under heavy development with functionality being added on a daily / weekly / monthly basis.  You might want to install directly from the latest version of the Git `master` branch rather than waiting for a release that has the feature you need.  For this, run:\n",
    "```\n",
    "python -m pip install git+https://github.com/dask/dask-jobqueue@<git-ref>\n",
    "``` \n",
    "with `<git-ref>` being the [Git reference](https://git-scm.com/book/en/v2/Git-Internals-Git-References) you want to install.  While this can be `master`, it is recommended to note an explicit commit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting help\n",
    "\n",
    "- A good first step is _reading the [manual](http://jobqueue.dask.org)_.  This will get you accustomed to the jargon used, specific terms, and give you a broad overview of what to expect / not to expect from the package. (You can read the entire docs including skimming the API defs in less than a hour.)Please make sure to also \n",
    "\n",
    "- Secondly, the [`[dask]` tag on stackoverflos](https://stackoverflow.com/questions/tagged/dask) might be a good resource.\n",
    "\n",
    "- Furthermore, the [dask-jobqueue issue tracker](https://github.com/dask/dask-jobqueue/issues) is a good place for usage questions.  (Often, it's advisable to search existing issues / pull requests. Somebody else might have had the same problem.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How this works\n",
    "\n",
    "(There's example code for most of the cluster classes supported by Dask-Jpbqueue [in the docs](http://jobqueue.dask.org/en/stable/examples.html).)\n",
    "\n",
    "In short, to set up a Dask scheduler and be ready to start jobs providing workers, run something like:\n",
    "```python\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "cluster = SLURMCluster(processes=4,\n",
    "                       threads=2,\n",
    "                       memory=\"16GB\",\n",
    "                       project=\"project_id\",\n",
    "                       walltime=\"01:00:00\",\n",
    "                       queue=\"batch\")\n",
    "```\n",
    "\n",
    "This will craete a Dask scheduler and wait for you to scale the cluster up using, e.g.,\n",
    "```python\n",
    "cluster.scale(8)\n",
    "```\n",
    "\n",
    "This will lead to the submission of a sufficient number of SLURM jobs to provide 8 workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "While it is perfectly possible to directly provide all the keyword args at initialization of the cluster, it is much easier to create a [configuration file](http://jobqueue.dask.org/en/stable/configuration.html) containing all or most of the info.  To get the best performance on your cluster, it is recommended to get the advice of an admin who might provide hints on the best network **`interface`** to use for inter-worker communication of tell you what to use as high-bandwidth **`local_directory`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging\n",
    "\n",
    "There's [info in the docs](http://jobqueue.dask.org/en/stable/debug.html).\n",
    "\n",
    "One thing that might help you initially is the ability to see the job script that will be submitted to the job scheduler:\n",
    "```python\n",
    "print(cluster.job_script())\n",
    "```\n",
    "\n",
    "A typical job script will loke similar to this:\n",
    "```shell\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "#SBATCH -J dask-worker\n",
    "#SBATCH -p batch\n",
    "#SBATCH -n 1\n",
    "#SBATCH --cpus-per-task=24\n",
    "#SBATCH --mem=94G\n",
    "#SBATCH -t 00:30:00\n",
    "JOB_ID=${SLURM_JOB_ID%;*}\n",
    "\n",
    "/path/to/python -m distributed.cli.dask_worker tcp://10.11.12.13:38814 \\\n",
    "    --nthreads 12 --nprocs 2 --memory-limit 50.00GB --name dask-worker--${JOB_ID}-- \\\n",
    "    --death-timeout 15s --local-directory /tmp --interface ib0\n",
    "    \n",
    "```\n",
    "\n",
    "If you have trouble in spinning up a cluster at all, your admins might be the best persons to debug this job script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring your jobs\n",
    "\n",
    "To see what your Dask-Jobqueue cluster is doing to the HPC job scheduler, a few shell commands might come in handy:\n",
    "\n",
    "See all you jobs with:\n",
    "\n",
    "```shell\n",
    "squeue | grep ${USER}\n",
    "```\n",
    "\n",
    "or wrap it in a `watch` (but make sure to be patient and set a responsible interval with the `-n`-flag:\n",
    "\n",
    "```shell\n",
    "watch -n 30 \"squeue | grep ${USER}\"\n",
    "```\n",
    "\n",
    "Get a quick overview of the number of pending (PD), running (R), cancelling (CG), etc. jobs with\n",
    "```shell\n",
    "watch -n 10 \"squeue | grep $USER | awk '{print \\$5}' | sort | uniq -c | paste -s\"\n",
    "```\n",
    "\n",
    "Monitor all your processes with either\n",
    "```shell\n",
    "top -u ${USER}\n",
    "```\n",
    "or\n",
    "\n",
    "```shell\n",
    "htop -u ${USER}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dask_jobqueue_workshop]",
   "language": "python",
   "name": "conda-env-dask_jobqueue_workshop-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
