{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning adaptivity of Dask clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the prior examples, we have seen basic adaptivity and manual scaling.  Here, we'll see how to adapt the dask cluster to approximately meet a target duration.  This will allow for switching between truely interactive work (where a user wants to see results immediately to decide about the next steps) and workloads where response time is of a lower priority."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a Slurm cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/docrep/__init__.py:341: MatplotlibDeprecationWarning: \n",
      "The dedent function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use inspect.cleandoc instead.\n",
      "  s = dedents('\\n' + '\\n'.join(lines[first:]))\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    cores=24,\n",
    "    processes=2,\n",
    "    memory=\"100GB\",\n",
    "    shebang='#!/usr/bin/env bash',\n",
    "    queue=\"batch\",\n",
    "    walltime=\"00:30:00\",\n",
    "    local_directory='/tmp',\n",
    "    death_timeout=\"15s\",\n",
    "    interface=\"ib0\",\n",
    "    log_directory=\"$SCRATCH_cecam/$USER/dask_jobqueue_logs/\",\n",
    "    project=\"ecam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://10.80.32.36:43926\n",
       "  <li><b>Dashboard: </b><a href='http://10.80.32.36:8787/status' target='_blank'>http://10.80.32.36:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.80.32.36:43926' processes=0 cores=0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some artifical workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_for_approx_n_seconds(n):\n",
    "    n += random() / 5\n",
    "    sleep(n)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import bag as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.99 s, sys: 517 ms, total: 7.51 s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "N = 200\n",
    "\n",
    "ns = db.from_sequence((1.0 for n in range(N)), npartitions=N)\n",
    "ns = ns.map(run_for_approx_n_seconds).compute();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More detailed adaptivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check docstring of distributed.Adaptive for keywords\n",
    "ca = cluster.adapt(\n",
    "    minimum=2, maximum=40,\n",
    "    target_duration=\"360s\",  # measured in CPUtime per worker\n",
    "    scale_factor=1);\n",
    "\n",
    "sleep(4)  # Allow for scale-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 1.3 s, total: 14.6 s\n",
      "Wall time: 43.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "N = 1000\n",
    "\n",
    "ns = db.from_sequence((3.0 for n in range(N)), npartitions=N)\n",
    "ns = ns.map(run_for_approx_n_seconds).compute();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(4)  # allow for scale-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 865 ms, total: 11.4 s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "N = 500\n",
    "\n",
    "ns = db.from_sequence((3.0 for n in range(N)), npartitions=N)\n",
    "ns = ns.map(run_for_approx_n_seconds).compute();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(4)  # allow for scale-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.32 s, sys: 280 ms, total: 3.6 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "N = 300\n",
    "\n",
    "ns = db.from_sequence((3.0 for n in range(N)), npartitions=N)\n",
    "ns = ns.map(run_for_approx_n_seconds).compute();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(4)  # allow for scale-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 s, sys: 1.33 s, total: 16.1 s\n",
      "Wall time: 51.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "N = 5000\n",
    "\n",
    "ns = db.from_sequence((1.0 for n in range(N)), npartitions=int(N / 5))\n",
    "ns = ns.map(run_for_approx_n_seconds).compute();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000013221436481\n",
      "CPU times: user 1min 2s, sys: 5.48 s, total: 1min 8s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print((da.random.normal(size=(5000e9 / 8, ), chunks=(500e6 / 8, )) ** 2).mean().compute());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://10.80.32.36:43926\n",
       "  <li><b>Dashboard: </b><a href='http://10.80.32.36:8787/status' target='_blank'>http://10.80.32.36:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>40</li>\n",
       "  <li><b>Cores: </b>480</li>\n",
       "  <li><b>Memory: </b>2.00 TB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.80.32.36:43926' processes=40 cores=480>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check docstring of distributed.Adaptive for keywords\n",
    "ca = cluster.adapt(\n",
    "    minimum=2, maximum=60,\n",
    "    target_duration=\"360s\",  # measured in CPUtime per worker\n",
    "    scale_factor=2);\n",
    "\n",
    "sleep(4)  # Allow for scale-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = da.random.normal(size=(200e9 / 8, ), chunks=(200e6 / 8, ))\n",
    "x = x.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "JobQueueCluster.scale_up was called with a number of workers lower that what is already running or pending\n",
      "tornado.application - ERROR - Multiple exceptions in yield list\n",
      "Traceback (most recent call last):\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 501, in callback\n",
      "    result_list.append(f.result())\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/core.py\", line 727, in send_recv_from_rpc\n",
      "    result = yield send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/core.py\", line 545, in send_recv\n",
      "    raise Exception(response[\"text\"])\n",
      "Exception: [Errno 28] No space left on device: '/tmp/worker-tdx38bsp/storage/%28%27normal-8324de6c7736b5266ea57057ae80ee13%27%2C%20144%29'\n",
      "distributed.utils - ERROR - [Errno 28] No space left on device: '/tmp/worker-x10beu2s/storage/%28%27normal-8324de6c7736b5266ea57057ae80ee13%27%2C%20131%29'\n",
      "Traceback (most recent call last):\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/utils.py\", line 713, in log_errors\n",
      "    yield\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/scheduler.py\", line 3039, in retire_workers\n",
      "    delete=False,\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/scheduler.py\", line 2850, in replicate\n",
      "    for w, who_has in gathers.items()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 501, in callback\n",
      "    result_list.append(f.result())\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/core.py\", line 727, in send_recv_from_rpc\n",
      "    result = yield send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/core.py\", line 545, in send_recv\n",
      "    raise Exception(response[\"text\"])\n",
      "Exception: [Errno 28] No space left on device: '/tmp/worker-x10beu2s/storage/%28%27normal-8324de6c7736b5266ea57057ae80ee13%27%2C%20131%29'\n",
      "distributed.utils - ERROR - [Errno 28] No space left on device: '/tmp/worker-x10beu2s/storage/%28%27normal-8324de6c7736b5266ea57057ae80ee13%27%2C%20131%29'\n",
      "Traceback (most recent call last):\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/utils.py\", line 713, in log_errors\n",
      "    yield\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/deploy/adaptive.py\", line 270, in _retire_workers\n",
      "    workers=workers, remove=True, close_workers=True\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/scheduler.py\", line 3039, in retire_workers\n",
      "    delete=False,\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/scheduler.py\", line 2850, in replicate\n",
      "    for w, who_has in gathers.items()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 501, in callback\n",
      "    result_list.append(f.result())\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/core.py\", line 727, in send_recv_from_rpc\n",
      "    result = yield send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/core.py\", line 545, in send_recv\n",
      "    raise Exception(response[\"text\"])\n",
      "Exception: [Errno 28] No space left on device: '/tmp/worker-x10beu2s/storage/%28%27normal-8324de6c7736b5266ea57057ae80ee13%27%2C%20131%29'\n",
      "tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <zmq.eventloop.ioloop.ZMQIOLoop object at 0x2ab23bc1bfd0>>, <Future finished exception=Exception(\"[Errno 28] No space left on device: '/tmp/worker-x10beu2s/storage/%28%27normal-8324de6c7736b5266ea57057ae80ee13%27%2C%20131%29'\")>)\n",
      "Traceback (most recent call last):\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/ioloop.py\", line 767, in _discard_future_result\n",
      "    future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/deploy/adaptive.py\", line 362, in _adapt\n",
      "    workers = yield self._retire_workers(workers=recommendations[\"workers\"])\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/deploy/adaptive.py\", line 270, in _retire_workers\n",
      "    workers=workers, remove=True, close_workers=True\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/scheduler.py\", line 3039, in retire_workers\n",
      "    delete=False,\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/scheduler.py\", line 2850, in replicate\n",
      "    for w, who_has in gathers.items()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 501, in callback\n",
      "    result_list.append(f.result())\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/core.py\", line 727, in send_recv_from_rpc\n",
      "    result = yield send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/core.py\", line 545, in send_recv\n",
      "    raise Exception(response[\"text\"])\n",
      "Exception: [Errno 28] No space left on device: '/tmp/worker-x10beu2s/storage/%28%27normal-8324de6c7736b5266ea57057ae80ee13%27%2C%20131%29'\n"
     ]
    }
   ],
   "source": [
    "wait(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0mpostcomputes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, restrictions, loose_restrictions, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2543\u001b[0m                     \u001b[0mshould_rejoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2544\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2545\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2546\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2547\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, maxsize, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                 \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 \u001b[0mlocal_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1800\u001b[0;31m                 \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m             )\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(x.mean().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete listing of software used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: module: line 1: syntax error: unexpected end of file\n",
      "/usr/bin/sh: error importing function definition for `BASH_FUNC_module'\n",
      "/usr/bin/sh: jutil: line 1: syntax error: unexpected end of file\n",
      "/usr/bin/sh: error importing function definition for `BASH_FUNC_jutil'\n",
      "/usr/bin/sh: ml: line 1: syntax error: unexpected end of file\n",
      "/usr/bin/sh: error importing function definition for `BASH_FUNC_ml'\n",
      "Package            Version          \n",
      "------------------ -----------------\n",
      "asciitree          0.3.3            \n",
      "aspy.yaml          1.2.0            \n",
      "backcall           0.1.0            \n",
      "bokeh              1.1.0            \n",
      "certifi            2019.3.9         \n",
      "cfgv               1.6.0            \n",
      "cftime             1.0.3.4          \n",
      "Click              7.0              \n",
      "cloudpickle        1.0.0            \n",
      "cycler             0.10.0           \n",
      "cytoolz            0.9.0.1          \n",
      "dask               1.2.0            \n",
      "dask-jobqueue      0.4.1+32.g9c3371d\n",
      "decorator          4.4.0            \n",
      "distributed        1.27.1           \n",
      "docrep             0.2.5            \n",
      "fasteners          0.14.1           \n",
      "heapdict           1.0.0            \n",
      "identify           1.4.3            \n",
      "importlib-metadata 0.13             \n",
      "ipykernel          5.1.1            \n",
      "ipython            7.5.0            \n",
      "ipython-genutils   0.2.0            \n",
      "jedi               0.13.3           \n",
      "Jinja2             2.10.1           \n",
      "jupyter-client     5.2.4            \n",
      "jupyter-core       4.4.0            \n",
      "kiwisolver         1.1.0            \n",
      "llvmlite           0.28.0           \n",
      "locket             0.2.0            \n",
      "MarkupSafe         1.1.1            \n",
      "matplotlib         3.1.0            \n",
      "monotonic          1.5              \n",
      "msgpack            0.6.1            \n",
      "netCDF4            1.5.1.2          \n",
      "nodeenv            1.3.3            \n",
      "numba              0.43.1           \n",
      "numcodecs          0.6.3            \n",
      "numpy              1.16.3           \n",
      "olefile            0.46             \n",
      "packaging          19.0             \n",
      "pandas             0.24.2           \n",
      "parso              0.4.0            \n",
      "partd              0.3.9            \n",
      "patsy              0.5.1            \n",
      "pexpect            4.7.0            \n",
      "pickleshare        0.7.5            \n",
      "Pillow             6.0.0            \n",
      "pip                19.1             \n",
      "pre-commit         1.16.1           \n",
      "prompt-toolkit     2.0.9            \n",
      "psutil             5.6.2            \n",
      "ptyprocess         0.6.0            \n",
      "Pygments           2.4.0            \n",
      "pyparsing          2.4.0            \n",
      "python-dateutil    2.8.0            \n",
      "pytz               2019.1           \n",
      "PyYAML             5.1              \n",
      "pyzmq              18.0.1           \n",
      "scipy              1.3.0            \n",
      "seaborn            0.9.0            \n",
      "setuptools         41.0.1           \n",
      "six                1.12.0           \n",
      "sortedcontainers   2.1.0            \n",
      "statsmodels        0.9.0            \n",
      "tblib              1.4.0            \n",
      "toml               0.10.0           \n",
      "toolz              0.9.0            \n",
      "tornado            6.0.2            \n",
      "traitlets          4.3.2            \n",
      "virtualenv         16.6.0           \n",
      "wcwidth            0.1.7            \n",
      "wheel              0.33.4           \n",
      "xarray             0.12.1           \n",
      "zarr               2.3.1            \n",
      "zict               0.1.4            \n",
      "zipp               0.5.1            \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: module: line 1: syntax error: unexpected end of file\n",
      "/usr/bin/sh: error importing function definition for `BASH_FUNC_module'\n",
      "/usr/bin/sh: jutil: line 1: syntax error: unexpected end of file\n",
      "/usr/bin/sh: error importing function definition for `BASH_FUNC_jutil'\n",
      "/usr/bin/sh: ml: line 1: syntax error: unexpected end of file\n",
      "/usr/bin/sh: error importing function definition for `BASH_FUNC_ml'\n",
      "# This file may be used to create an environment using:\n",
      "# $ conda create --name <env> --file <this file>\n",
      "# platform: linux-64\n",
      "@EXPLICIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tornado.application - ERROR - Multiple exceptions in yield list\n",
      "Traceback (most recent call last):\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 501, in callback\n",
      "    result_list.append(f.result())\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/core.py\", line 727, in send_recv_from_rpc\n",
      "    result = yield send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/core.py\", line 545, in send_recv\n",
      "    raise Exception(response[\"text\"])\n",
      "Exception: [Errno 28] No space left on device\n",
      "distributed.utils - ERROR - [Errno 28] No space left on device\n",
      "Traceback (most recent call last):\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/utils.py\", line 713, in log_errors\n",
      "    yield\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/scheduler.py\", line 3039, in retire_workers\n",
      "    delete=False,\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/scheduler.py\", line 2850, in replicate\n",
      "    for w, who_has in gathers.items()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 501, in callback\n",
      "    result_list.append(f.result())\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/core.py\", line 727, in send_recv_from_rpc\n",
      "    result = yield send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/core.py\", line 545, in send_recv\n",
      "    raise Exception(response[\"text\"])\n",
      "Exception: [Errno 28] No space left on device\n",
      "distributed.utils - ERROR - [Errno 28] No space left on device\n",
      "Traceback (most recent call last):\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/utils.py\", line 713, in log_errors\n",
      "    yield\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/deploy/adaptive.py\", line 270, in _retire_workers\n",
      "    workers=workers, remove=True, close_workers=True\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/scheduler.py\", line 3039, in retire_workers\n",
      "    delete=False,\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/scheduler.py\", line 2850, in replicate\n",
      "    for w, who_has in gathers.items()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 501, in callback\n",
      "    result_list.append(f.result())\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/core.py\", line 727, in send_recv_from_rpc\n",
      "    result = yield send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/core.py\", line 545, in send_recv\n",
      "    raise Exception(response[\"text\"])\n",
      "Exception: [Errno 28] No space left on device\n",
      "tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <zmq.eventloop.ioloop.ZMQIOLoop object at 0x2ab23bc1bfd0>>, <Future finished exception=Exception('[Errno 28] No space left on device')>)\n",
      "Traceback (most recent call last):\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/ioloop.py\", line 767, in _discard_future_result\n",
      "    future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/deploy/adaptive.py\", line 362, in _adapt\n",
      "    workers = yield self._retire_workers(workers=recommendations[\"workers\"])\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/deploy/adaptive.py\", line 270, in _retire_workers\n",
      "    workers=workers, remove=True, close_workers=True\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/scheduler.py\", line 3039, in retire_workers\n",
      "    delete=False,\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/scheduler.py\", line 2850, in replicate\n",
      "    for w, who_has in gathers.items()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 501, in callback\n",
      "    result_list.append(f.result())\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 736, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/core.py\", line 727, in send_recv_from_rpc\n",
      "    result = yield send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 729, in run\n",
      "    value = future.result()\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/p/project/cecam/rath1/miniconda3_20190521/envs/dask_jobqueue_workshop/lib/python3.7/site-packages/distributed/core.py\", line 545, in send_recv\n",
      "    raise Exception(response[\"text\"])\n",
      "Exception: [Errno 28] No space left on device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://conda.anaconda.org/conda-forge/linux-64/git-lfs-2.7.2-0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/ca-certificates-2019.3.9-hecc5488_0.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/libgcc-ng-8.2.0-hdf63c60_1.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/libgfortran-ng-7.3.0-hdf63c60_0.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/libstdcxx-ng-8.2.0-hdf63c60_1.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/bzip2-1.0.6-h14c3975_1002.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/expat-2.2.5-hf484d3e_1002.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/icu-58.2-hf484d3e_1000.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/jpeg-9c-h14c3975_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libffi-3.2.1-he1b5a44_1006.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libiconv-1.15-h516909a_1005.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libsodium-1.0.16-h14c3975_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libuuid-2.32.1-h14c3975_1000.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/ncurses-6.1-hf484d3e_1002.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/openblas-0.3.6-h6e990d7_2.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/openssl-1.1.1b-h14c3975_1.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/pcre-8.41-hf484d3e_1003.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/perl-5.26.2-h516909a_1006.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/pthread-stubs-0.4-h14c3975_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/xorg-libxau-1.0.9-h14c3975_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/xorg-libxdmcp-1.1.3-h516909a_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/xz-5.2.4-h14c3975_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/yaml-0.1.7-h14c3975_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/zlib-1.2.11-h14c3975_1004.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/gettext-0.19.8.1-hc5be6a0_1002.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/hdf4-4.2.13-h9a582f1_1002.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/hdf5-1.10.4-nompi_h3c11f04_1106.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libblas-3.8.0-10_openblas.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libedit-3.1.20170329-hf8c457e_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libpng-1.6.37-hed695b0_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libssh2-1.8.2-h22169c7_2.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libtiff-4.0.10-h648cc4a_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libxcb-1.13-h14c3975_1002.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libxml2-2.9.9-h13577e0_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/readline-7.0-hf8c457e_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/tk-8.6.9-h84994c4_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/zeromq-4.3.1-hf484d3e_1000.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/freetype-2.10.0-he983fc9_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/glib-2.58.3-hf63aee3_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/krb5-1.16.3-h05b26f9_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libcblas-3.8.0-10_openblas.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/liblapack-3.8.0-10_openblas.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/sqlite-3.26.0-h67949de_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/dbus-1.13.6-he372182_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/fontconfig-2.13.1-he4413a7_1000.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/gstreamer-1.14.4-h66beb1c_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libcurl-7.64.1-hda55be3_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/python-3.7.3-h5b0a415_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/asciitree-0.3.3-py_2.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/backcall-0.1.0-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/certifi-2019.3.9-py37_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/click-7.0-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/cloudpickle-1.0.0-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/curl-7.64.1-hf8cf82a_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/dask-core-1.2.0-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/decorator-4.4.0-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/gst-plugins-base-1.14.4-hdf3bae2_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/heapdict-1.0.0-py37_1000.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/ipython_genutils-0.2.0-py_1.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/kiwisolver-1.1.0-py37hc9558a2_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/llvmlite-0.28.0-py37hdbcaa40_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/locket-0.2.0-py_2.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/markupsafe-1.1.1-py37h14c3975_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/monotonic-1.5-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/msgpack-python-0.6.1-py37h6bb024c_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/numpy-1.16.3-py37he5ce36f_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/olefile-0.46-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/parso-0.4.0-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/pickleshare-0.7.5-py37_1000.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/psutil-5.6.2-py37h516909a_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/ptyprocess-0.6.0-py_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/pyparsing-2.4.0-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/pytz-2019.1-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/pyyaml-5.1-py37h14c3975_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/pyzmq-18.0.1-py37hc4ba49a_1.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/sip-4.19.8-py37hf484d3e_1000.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/six-1.12.0-py37_1000.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/sortedcontainers-2.1.0-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/tblib-1.4.0-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/toolz-0.9.0-py_1.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/tornado-6.0.2-py37h516909a_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/wcwidth-0.1.7-py_1.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/cftime-1.0.3.4-py37hd352d35_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/cycler-0.10.0-py_1.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/cytoolz-0.9.0.1-py37h14c3975_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/fasteners-0.14.1-py_3.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/git-2.21.0-pl526h2882143_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/jedi-0.13.3-py37_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libnetcdf-4.6.2-hbdf4f91_1001.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/numba-0.43.1-py37hf2d7682_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/numcodecs-0.6.3-py37hf484d3e_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/packaging-19.0-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/partd-0.3.9-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/pexpect-4.7.0-py37_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/pillow-6.0.0-py37he7afcd5_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/python-dateutil-2.8.0-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/qt-5.9.7-h52cfd70_1.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/scipy-1.3.0-py37hab63836_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/setuptools-41.0.1-py37_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/traitlets-4.3.2-py37_1000.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/zict-0.1.4-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/distributed-1.27.1-py37_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/jinja2-2.10.1-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/jupyter_core-4.4.0-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/matplotlib-base-3.1.0-py37h5f35d83_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/netcdf4-1.5.1.2-py37had58050_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/pandas-0.24.2-py37hf484d3e_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/patsy-0.5.1-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/pygments-2.4.0-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/pyqt-5.9.2-py37hcca6a23_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/wheel-0.33.4-py37_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/zarr-2.3.1-py37_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/bokeh-1.1.0-py37_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/jupyter_client-5.2.4-py_3.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/matplotlib-3.1.0-py37_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/pip-19.1-py37_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/prompt_toolkit-2.0.9-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/statsmodels-0.9.0-py37h3010b51_1000.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/xarray-0.12.1-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/dask-1.2.0-py_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/ipython-7.5.0-py37h24bf2e0_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/seaborn-0.9.0-py_1.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/ipykernel-5.1.1-py37h24bf2e0_0.tar.bz2\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda list --explicit"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dask_jobqueue_workshop]",
   "language": "python",
   "name": "conda-env-dask_jobqueue_workshop-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
